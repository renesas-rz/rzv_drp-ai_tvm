diff --git TopFormer/tools/test.py TopFormer/tools/eval_with_pruned_model.py
old mode 100644
new mode 100755
index 7d855a7..0b87c5c
--- TopFormer/tools/test.py
+++ TopFormer/tools/eval_with_pruned_model.py
@@ -1,3 +1,21 @@
+#######################################################################################################################
+# DISCLAIMER
+# This software is supplied by Renesas Electronics Corporation and is only intended for use with Renesas products. No
+# other uses are authorized. This software is owned by Renesas Electronics Corporation and is protected under all
+# applicable laws, including copyright laws.
+# THIS SOFTWARE IS PROVIDED "AS IS" AND RENESAS MAKES NO WARRANTIES REGARDING
+# THIS SOFTWARE, WHETHER EXPRESS, IMPLIED OR STATUTORY, INCLUDING BUT NOT LIMITED TO WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. ALL SUCH WARRANTIES ARE EXPRESSLY DISCLAIMED. TO THE MAXIMUM
+# EXTENT PERMITTED NOT PROHIBITED BY LAW, NEITHER RENESAS ELECTRONICS CORPORATION NOR ANY OF ITS AFFILIATED COMPANIES
+# SHALL BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES FOR ANY REASON RELATED TO
+# THIS SOFTWARE, EVEN IF RENESAS OR ITS AFFILIATES HAVE BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.
+# Renesas reserves the right, without notice, to make changes to this software and to discontinue the availability of
+# this software. By using this software, you agree to the additional terms and conditions found by accessing the
+# following link:
+# http://www.renesas.com/disclaimer
+#
+# Copyright (C) 2025 Renesas Electronics Corporation. All rights reserved.
+#######################################################################################################################
 # Copyright (c) OpenMMLab. All rights reserved.
 import argparse
 import os
@@ -16,8 +34,38 @@ from mmcv.utils import DictAction
 from mmseg.apis import multi_gpu_test, single_gpu_test
 from mmseg.datasets import build_dataloader, build_dataset
 from mmseg.models import build_segmentor
+from drpai_compaction_tool.pytorch import load_pruned_state_dict, \
+                                          get_model_info
+                                          
+import numpy as np
+def demo_mm_inputs(input_shape, num_classes):
+    """Create a superset of inputs needed to run test or train batches.
 
-
+    Args:
+        input_shape (tuple):
+            input batch dimensions
+        num_classes (int):
+            number of semantic classes
+    """
+    (N, C, H, W) = input_shape
+    rng = np.random.RandomState(0)
+    imgs = rng.rand(*input_shape)
+    segs = rng.randint(
+        low=0, high=num_classes - 1, size=(N, 1, H, W)).astype(np.uint8)
+    img_metas = [{
+        'img_shape': (H, W, C),
+        'ori_shape': (H, W, C),
+        'pad_shape': (H, W, C),
+        'filename': '<demo>.png',
+        'scale_factor': 1.0,
+        'flip': False,
+    } for _ in range(N)]
+    mm_inputs = {
+        'img': torch.FloatTensor(imgs).requires_grad_(True),
+        'img_metas': img_metas,
+        'gt_semantic_seg': torch.LongTensor(segs)
+    }
+    return mm_inputs
 def parse_args():
     parser = argparse.ArgumentParser(
         description='mmseg test (and eval) a model')
@@ -71,6 +119,9 @@ def parse_args():
         default=0.5,
         help='Opacity of painted segmentation map. In (0, 1] range.')
     parser.add_argument('--local_rank', type=int, default=0)
+    # Modified by Renesas
+    parser.add_argument('--is_pruned_weight', action='store_true',
+                        help='When converting the model with pruned weight, please specify this option')
     args = parser.parse_args()
     if 'LOCAL_RANK' not in os.environ:
         os.environ['LOCAL_RANK'] = str(args.local_rank)
@@ -137,7 +188,20 @@ def main():
     fp16_cfg = cfg.get('fp16', None)
     if fp16_cfg is not None:
         wrap_fp16_model(model)
-    checkpoint = load_checkpoint(model, args.checkpoint, map_location='cpu')
+    if args.is_pruned_weight:
+        demo_inputs =  demo_mm_inputs((1,3,512,512), num_classes=150)
+        data = {
+            'img': demo_inputs['img'].cuda(),
+            'img_metas': demo_inputs['img_metas'],
+            'gt_semantic_seg': demo_inputs['gt_semantic_seg'].cuda()
+        }
+        # load the model state dict
+        checkpoint = torch.load(args.checkpoint, map_location='cpu')
+        load_pruned_state_dict(model, checkpoint['state_dict'])
+        # Confirming the result of pruning.
+        print(get_model_info(model.cuda(), input_data=data))
+    else:
+        checkpoint = load_checkpoint(model, args.checkpoint, map_location='cpu')
     if 'CLASSES' in checkpoint.get('meta', {}):
         model.CLASSES = checkpoint['meta']['CLASSES']
     else:
