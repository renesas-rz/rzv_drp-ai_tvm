
# Compile Reference

## Frontend APIs
You can refer to the official TVM site for how to use the frontend of compile script. Please check below site.   
[Compile Deep Learning Models](https://tvm.apache.org/docs/how_to/compile_models/index.html)   


## Backend APIs
### Function   

|API |Note|
|---|---|
| mera.drp.build() | Compile relay to runtime object files.|   


### Sample code:   

```py
from tvm.relay.mera import drp
drp.build(mod, \
               params, \
               "arm", \
               drp_config_runtime, \
               output_dir=output_dir, \
               disable_concat = opts["disable_concat"], \
               cpu_data_type="float16"
               )
```

| Index | Argument       | Note                                              |
|:-:|--------------------|---------------------------------------------------|
| 1 | mod                | IR format AI model generated by TVM frontend.     |
| 2 | params             | Parameter date  generated by TVM frontend.        |
| 3 | "arm"              | Target architecture. Supported "arm" only.        |
| 4 | drp_config_runtime | See [DRP runtime config](#DRP-runtime-config)     |
| 5 | output_dir         | Output directory to save compile results.         |
| 6 | disable_concat     | Compile optimization option. Default: False       |
| 6 | cpu_data_type      | Data type for processing by CPU. Default: float16 |

### DRP runtime config
+ Sample code:
```py
    drp_config_runtime = {
        "interpreter": False,
        "addr_map_start": 0x0,
        "toolchain_dir": opts["drp_compiler_dir"],
        "sdk_root": opts["toolchain_dir"]
    }
```   

| Argument | Note |
|----|----|
| "interpreter"   | Interpreter mode setting. True : Run inference on PC. False : Make runtime object files to run target RZ/ V board.|
| "addr_map_start"| Start address assigned for DRP-AI |
|"toolchain_dir"  | DRP-AI Translator installed directory |
|"sdk_root"       | SDK(Cross compiler) installed directory. |

Keep **0x0** to "addr_map_start" for Renesas RZ/V Evaluation Board Kit.


----
## Appendix 1 : Argments of sample scripts

|option|Note|
|----|----|
|-o/--output_dir|Output directory to save compile results.|
|-i/--input_name|AI model input node name. (Not required for pytorch models)|
|-s/--input_shape|AI model input node shape|
|[option]-d/--drp_compiler_dir|DRP-AI Translator installed directory. This argument can be omitted by setting environment variables as shown follwoing: "export TRANSLATOR=<.../drp-ai_translator> "|
|[option]-t/--toolchain_dir|SDK(Cross compiler) installed directory. This argument can be omitted by setting environment variables as shown follwoing: "export SDK=</opt/poky/3.1.21>"|
|[option]--level | Optimization level at compile. "1" is the default and compiles with optimal settings. If "0" is set to this option,  complex models can be deployed, but inference speed is slower.|

[*1]: DRP-AI TVM is powered by EdgeCortix MERAâ„¢ Compiler Framework.
